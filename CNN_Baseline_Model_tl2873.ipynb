{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import ast\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw \n",
    "from tqdm import tqdm\n",
    "from dask import bag\n",
    "train_dir = '/Users/taoli/Documents/Columbia_University/W4995_Deep_Learning/Project/train_simplified'\n",
    "#print(os.listdir(train_dir))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to suppress some matplotlib deprecation warnings\n",
    "import ast\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countrycode</th>\n",
       "      <th>drawing</th>\n",
       "      <th>recognized</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6538378709303296</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[0, 28, 50, 73, 88, 94, 101, 101, 98, 100, 1...</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-01 03:23:58.188330</td>\n",
       "      <td>roller_coaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974848176553984</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[0, 50, 78, 126, 142, 152, 157, 157, 141, 12...</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-11 04:04:09.020040</td>\n",
       "      <td>roller_coaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822246901776384</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[2, 0, 17, 42, 68, 97, 120, 140, 151, 151, 1...</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-15 03:05:49.143180</td>\n",
       "      <td>roller_coaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572615668236288</th>\n",
       "      <td>GB</td>\n",
       "      <td>[[[192, 130, 101, 72, 0], [4, 99, 132, 148, 17...</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-18 21:36:45.223520</td>\n",
       "      <td>roller_coaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266343907131392</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[9, 11, 19, 41, 114, 136, 153, 167, 179, 230...</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-27 18:41:09.065050</td>\n",
       "      <td>roller_coaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 countrycode  \\\n",
       "key_id                         \n",
       "6538378709303296          US   \n",
       "4974848176553984          US   \n",
       "5822246901776384          US   \n",
       "5572615668236288          GB   \n",
       "6266343907131392          US   \n",
       "\n",
       "                                                            drawing  \\\n",
       "key_id                                                                \n",
       "6538378709303296  [[[0, 28, 50, 73, 88, 94, 101, 101, 98, 100, 1...   \n",
       "4974848176553984  [[[0, 50, 78, 126, 142, 152, 157, 157, 141, 12...   \n",
       "5822246901776384  [[[2, 0, 17, 42, 68, 97, 120, 140, 151, 151, 1...   \n",
       "5572615668236288  [[[192, 130, 101, 72, 0], [4, 99, 132, 148, 17...   \n",
       "6266343907131392  [[[9, 11, 19, 41, 114, 136, 153, 167, 179, 230...   \n",
       "\n",
       "                  recognized                   timestamp            word  \n",
       "key_id                                                                    \n",
       "6538378709303296        True  2017-03-01 03:23:58.188330  roller_coaster  \n",
       "4974848176553984        True  2017-03-11 04:04:09.020040  roller_coaster  \n",
       "5822246901776384        True  2017-03-15 03:05:49.143180  roller_coaster  \n",
       "5572615668236288        True  2017-03-18 21:36:45.223520  roller_coaster  \n",
       "6266343907131392        True  2017-01-27 18:41:09.065050  roller_coaster  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(train_dir + '/roller coaster.csv',\n",
    "                   index_col='key_id',\n",
    "                   nrows=100)\n",
    "#data.head()\n",
    "data['word'] = data['word'].replace(' ', '_', regex=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfiles = os.listdir(train_dir)\n",
    "numstonames = {i: v[:-4].replace(\" \", \"_\") for i, v in enumerate(classfiles)} #adds underscores\n",
    "\n",
    "num_classes = 340    #340 max \n",
    "imheight, imwidth = 32, 32  \n",
    "ims_per_class = 2000  #max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    image = Image.new(\"P\", (256,256), color=255)\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0])-1):\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=0, width=5)\n",
    "    image = image.resize((imheight, imwidth))\n",
    "    return np.array(image)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [04:06<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#%% get train arrays\n",
    "train_grand = []\n",
    "class_paths = glob(train_dir+'/*.csv')\n",
    "for i,c in enumerate(tqdm(class_paths[0: num_classes])):\n",
    "    train = pd.read_csv(c, usecols=['drawing', 'recognized'], nrows=ims_per_class*5//4)\n",
    "    train = train[train.recognized == True].head(ims_per_class)\n",
    "    imagebag = bag.from_sequence(train.drawing.values).map(draw_it) \n",
    "    trainarray = np.array(imagebag.compute())  # PARALLELIZE\n",
    "    trainarray = np.reshape(trainarray, (ims_per_class, -1))    \n",
    "    labelarray = np.full((train.shape[0], 1), i)\n",
    "    trainarray = np.concatenate((labelarray, trainarray), axis=1)\n",
    "    train_grand.append(trainarray)\n",
    "    \n",
    "train_grand = np.array([train_grand.pop() for i in np.arange(num_classes)]) #less memory than np.concatenate\n",
    "train_grand = train_grand.reshape((-1, (imheight*imwidth+1)))\n",
    "\n",
    "del trainarray\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612000, 340) \n",
      " (612000, 32, 32, 1) \n",
      " (68000, 340) \n",
      " (68000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# memory-friendly alternative to train_test_split?\n",
    "valfrac = 0.1\n",
    "cutpt = int(valfrac * train_grand.shape[0])\n",
    "\n",
    "np.random.shuffle(train_grand)\n",
    "y_train, X_train = train_grand[cutpt: , 0], train_grand[cutpt: , 1:]\n",
    "y_val, X_val = train_grand[0:cutpt, 0], train_grand[0:cutpt, 1:] #validation set is recognized==True\n",
    "\n",
    "del train_grand\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "X_train = X_train.reshape(X_train.shape[0], imheight, imwidth, 1)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "X_val = X_val.reshape(X_val.shape[0], imheight, imwidth, 1)\n",
    "\n",
    "print(y_train.shape, \"\\n\",\n",
    "      X_train.shape, \"\\n\",\n",
    "      y_val.shape, \"\\n\",\n",
    "      X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 680)               2785960   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 680)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 340)               231540    \n",
      "=================================================================\n",
      "Total params: 3,036,316\n",
      "Trainable params: 3,036,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(imheight, imwidth, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(680, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 612000 samples, validate on 68000 samples\n",
      "Epoch 1/22\n",
      "612000/612000 [==============================] - 1343s 2ms/step - loss: 3.0754 - acc: 0.3091 - top_3_accuracy: 0.4989 - val_loss: 2.1610 - val_acc: 0.4791 - val_top_3_accuracy: 0.6877\n",
      "Epoch 2/22\n",
      "612000/612000 [==============================] - 1350s 2ms/step - loss: 2.4891 - acc: 0.4061 - top_3_accuracy: 0.6185 - val_loss: 2.0020 - val_acc: 0.5080 - val_top_3_accuracy: 0.7202\n",
      "Epoch 3/22\n",
      "612000/612000 [==============================] - 1364s 2ms/step - loss: 2.3533 - acc: 0.4321 - top_3_accuracy: 0.6459 - val_loss: 2.0232 - val_acc: 0.5097 - val_top_3_accuracy: 0.7177\n",
      "Epoch 4/22\n",
      "612000/612000 [==============================] - 1386s 2ms/step - loss: 2.2778 - acc: 0.4465 - top_3_accuracy: 0.6613 - val_loss: 1.8988 - val_acc: 0.5336 - val_top_3_accuracy: 0.7409\n",
      "Epoch 5/22\n",
      "612000/612000 [==============================] - 1391s 2ms/step - loss: 2.2313 - acc: 0.4573 - top_3_accuracy: 0.6715 - val_loss: 1.8778 - val_acc: 0.5391 - val_top_3_accuracy: 0.7443\n",
      "Epoch 6/22\n",
      "612000/612000 [==============================] - 1399s 2ms/step - loss: 2.2034 - acc: 0.4613 - top_3_accuracy: 0.6764 - val_loss: 1.8564 - val_acc: 0.5422 - val_top_3_accuracy: 0.7503\n",
      "Epoch 7/22\n",
      "612000/612000 [==============================] - 1405s 2ms/step - loss: 2.1817 - acc: 0.4657 - top_3_accuracy: 0.6811 - val_loss: 1.8502 - val_acc: 0.5451 - val_top_3_accuracy: 0.7526\n",
      "Epoch 8/22\n",
      "612000/612000 [==============================] - 1407s 2ms/step - loss: 2.1686 - acc: 0.4689 - top_3_accuracy: 0.6835 - val_loss: 1.9015 - val_acc: 0.5397 - val_top_3_accuracy: 0.7473\n",
      "Epoch 9/22\n",
      "612000/612000 [==============================] - 1417s 2ms/step - loss: 2.1584 - acc: 0.4700 - top_3_accuracy: 0.6857 - val_loss: 1.8192 - val_acc: 0.5466 - val_top_3_accuracy: 0.7526\n",
      "Epoch 10/22\n",
      "612000/612000 [==============================] - 1429s 2ms/step - loss: 2.1515 - acc: 0.4723 - top_3_accuracy: 0.6875 - val_loss: 1.9328 - val_acc: 0.5349 - val_top_3_accuracy: 0.7437\n",
      "Epoch 11/22\n",
      "612000/612000 [==============================] - 1433s 2ms/step - loss: 2.1459 - acc: 0.4744 - top_3_accuracy: 0.6889 - val_loss: 1.8603 - val_acc: 0.5460 - val_top_3_accuracy: 0.7509\n",
      "Epoch 12/22\n",
      "612000/612000 [==============================] - 1437s 2ms/step - loss: 2.1429 - acc: 0.4738 - top_3_accuracy: 0.6890 - val_loss: 1.8071 - val_acc: 0.5507 - val_top_3_accuracy: 0.7558\n",
      "Epoch 13/22\n",
      "612000/612000 [==============================] - 1440s 2ms/step - loss: 2.1429 - acc: 0.4751 - top_3_accuracy: 0.6900 - val_loss: 1.8266 - val_acc: 0.5486 - val_top_3_accuracy: 0.7541\n",
      "Epoch 14/22\n",
      "612000/612000 [==============================] - 1440s 2ms/step - loss: 2.1391 - acc: 0.4759 - top_3_accuracy: 0.6908 - val_loss: 1.8414 - val_acc: 0.5452 - val_top_3_accuracy: 0.7491\n",
      "Epoch 15/22\n",
      "611968/612000 [============================>.] - ETA: 0s - loss: 2.1404 - acc: 0.4757 - top_3_accuracy: 0.6904\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "612000/612000 [==============================] - 1444s 2ms/step - loss: 2.1404 - acc: 0.4757 - top_3_accuracy: 0.6904 - val_loss: 1.8245 - val_acc: 0.5495 - val_top_3_accuracy: 0.7541\n",
      "Epoch 16/22\n",
      "612000/612000 [==============================] - 1447s 2ms/step - loss: 2.0189 - acc: 0.4991 - top_3_accuracy: 0.7123 - val_loss: 1.7871 - val_acc: 0.5592 - val_top_3_accuracy: 0.7633\n",
      "Epoch 17/22\n",
      "612000/612000 [==============================] - 1448s 2ms/step - loss: 1.9957 - acc: 0.5034 - top_3_accuracy: 0.7165 - val_loss: 1.7889 - val_acc: 0.5570 - val_top_3_accuracy: 0.7645\n",
      "Epoch 18/22\n",
      "612000/612000 [==============================] - 1449s 2ms/step - loss: 1.9851 - acc: 0.5044 - top_3_accuracy: 0.7184 - val_loss: 1.7528 - val_acc: 0.5623 - val_top_3_accuracy: 0.7658\n",
      "Epoch 19/22\n",
      "612000/612000 [==============================] - 1451s 2ms/step - loss: 1.9775 - acc: 0.5065 - top_3_accuracy: 0.7203 - val_loss: 1.7875 - val_acc: 0.5599 - val_top_3_accuracy: 0.7652\n",
      "Epoch 20/22\n",
      "612000/612000 [==============================] - 1455s 2ms/step - loss: 1.9703 - acc: 0.5077 - top_3_accuracy: 0.7209 - val_loss: 1.7363 - val_acc: 0.5663 - val_top_3_accuracy: 0.7698\n",
      "Epoch 21/22\n",
      "612000/612000 [==============================] - 1472s 2ms/step - loss: 1.9687 - acc: 0.5081 - top_3_accuracy: 0.7215 - val_loss: 1.7550 - val_acc: 0.5645 - val_top_3_accuracy: 0.7671\n",
      "Epoch 22/22\n",
      "612000/612000 [==============================] - 1502s 2ms/step - loss: 1.9655 - acc: 0.5091 - top_3_accuracy: 0.7232 - val_loss: 1.7546 - val_acc: 0.5664 - val_top_3_accuracy: 0.7682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3ae6ab70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_3_accuracy(x,y): \n",
    "    t3 = top_k_categorical_accuracy(x,y, 3)\n",
    "    return t3\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='auto', min_delta=0.005, cooldown=5, min_lr=0.0001)\n",
    "earlystop = EarlyStopping(monitor='val_top_3_accuracy', mode='max', patience=5) \n",
    "callbacks = [reduceLROnPlat, earlystop]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', top_3_accuracy])\n",
    "\n",
    "model.fit(x=X_train, y=y_train,\n",
    "          batch_size = 32,\n",
    "          epochs = 22,\n",
    "          validation_data = (X_val, y_val),\n",
    "          callbacks = callbacks,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:39<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "#%% get test set\n",
    "ttvlist = []\n",
    "reader = pd.read_csv('/Users/taoli/Documents/Columbia_University/W4995_Deep_Learning/Project/test_simplified.csv', index_col=['key_id'],\n",
    "    chunksize=2048)\n",
    "for chunk in tqdm(reader, total=55):\n",
    "    imagebag = bag.from_sequence(chunk.drawing.values).map(draw_it)\n",
    "    testarray = np.array(imagebag.compute())\n",
    "    testarray = np.reshape(testarray, (testarray.shape[0], imheight, imwidth, 1))\n",
    "    testpreds = model.predict(testarray, verbose=0)\n",
    "    ttvs = np.argsort(-testpreds)[:, 0:3]  # top 3\n",
    "    ttvlist.append(ttvs)\n",
    "    \n",
    "ttvarray = np.concatenate(ttvlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9000003627287624</th>\n",
       "      <td>radio motorbike bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000010688666847</th>\n",
       "      <td>sandwich hockey_puck belt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000023642890129</th>\n",
       "      <td>The_Great_Wall_of_China castle bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000038588854897</th>\n",
       "      <td>mountain tent triangle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000052667981386</th>\n",
       "      <td>campfire fireplace hedgehog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   word\n",
       "key_id                                                 \n",
       "9000003627287624                radio motorbike bicycle\n",
       "9000010688666847              sandwich hockey_puck belt\n",
       "9000023642890129  The_Great_Wall_of_China castle bridge\n",
       "9000038588854897                 mountain tent triangle\n",
       "9000052667981386            campfire fireplace hedgehog"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = pd.DataFrame({'first': ttvarray[:,0], 'second': ttvarray[:,1], 'third': ttvarray[:,2]})\n",
    "preds_df = preds_df.replace(numstonames)\n",
    "preds_df['words'] = preds_df['first'] + \" \" + preds_df['second'] + \" \" + preds_df['third']\n",
    "\n",
    "sub = pd.read_csv('/Users/taoli/Documents/Columbia_University/W4995_Deep_Learning/Project/sample_submission.csv', index_col=['key_id'])\n",
    "sub['word'] = preds_df.words.values\n",
    "sub.to_csv('subcnn_small.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preds_df', 30590222),\n",
       " ('sub', 9909531),\n",
       " ('ttvarray', 2692888),\n",
       " ('testpreds', 2185632),\n",
       " ('chunk', 1053432),\n",
       " ('data', 70120),\n",
       " ('labelarray', 16112),\n",
       " ('numstonames', 9320),\n",
       " ('class_paths', 3104),\n",
       " ('Sequential', 3096),\n",
       " ('classfiles', 2896),\n",
       " ('Dense', 2000),\n",
       " ('Dropout', 2000),\n",
       " ('Flatten', 2000),\n",
       " ('MaxPooling2D', 2000),\n",
       " ('EarlyStopping', 1464),\n",
       " ('ReduceLROnPlateau', 1464),\n",
       " ('ModelCheckpoint', 1056),\n",
       " ('Conv2D', 888),\n",
       " ('ttvlist', 528),\n",
       " ('c', 148),\n",
       " ('X_train', 144),\n",
       " ('X_val', 144),\n",
       " ('testarray', 144),\n",
       " ('draw_it', 136),\n",
       " ('top_3_accuracy', 136),\n",
       " ('top_k_categorical_accuracy', 136),\n",
       " ('train_dir', 136),\n",
       " ('ttvs', 112),\n",
       " ('y_train', 112),\n",
       " ('y_val', 112),\n",
       " ('Image', 80),\n",
       " ('ImageDraw', 80),\n",
       " ('bag', 80),\n",
       " ('callbacks', 80),\n",
       " ('keras', 80),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('plt', 80),\n",
       " ('style', 80),\n",
       " ('tf', 80),\n",
       " ('earlystop', 56),\n",
       " ('imagebag', 56),\n",
       " ('model', 56),\n",
       " ('reader', 56),\n",
       " ('reduceLROnPlat', 56),\n",
       " ('cutpt', 28),\n",
       " ('i', 28),\n",
       " ('imheight', 28),\n",
       " ('ims_per_class', 28),\n",
       " ('imwidth', 28),\n",
       " ('num_classes', 28),\n",
       " ('valfrac', 24)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not \n",
    "    x.startswith('_') and x not in sys.modules and x \n",
    "    not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
